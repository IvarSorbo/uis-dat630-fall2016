{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLM ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring a given document\n",
    "\n",
    "This method computes $\\log P(q|d) = \\sum_{i=1}^{|q|} \\log P(q_i|\\theta_d)$, where $q_i$ is a query term.\n",
    "\n",
    "The document language model is a mixture of field-level language models (substitute $t$ with $q_i$):\n",
    "\n",
    "$P(t|\\theta_d) = \\sum_i \\mu_i P(t|\\theta_{d_i})$\n",
    "\n",
    "where $mu_i$ are in `FIELD_WEIGHT`\n",
    "\n",
    "The field-level language models are empirical field LMs smoothed with a field background model (using Jelinek-Mercer smoothing)\n",
    "\n",
    "$P(t|\\theta_{d_i}) = (1-\\lambda) P(t|d_i) + \\lambda P(t|C_i)$\n",
    "\n",
    "where\n",
    "  - the empirical field LM $P(t|d_i)$ is the relative frequency of $t$ in the field\n",
    "  - the background field LM $P(t|C_i)$ can be computed using the provided `BackgroundLM` class (but it needs to be instantiated for each field)\n",
    "  - the same smoothing parameter $lambda$ is used for all fields (you could also use field-specific smoothing parameters $\\lambda_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_doc(doc_id, qterms):\n",
    "    # Get document termvectors (holds document term frequencies for each field)\n",
    "    tv = es.termvectors(index=INDEX_NAME, doc_type=DOC_TYPE, id=doc_id, fields=FIELDS,\n",
    "                                  term_statistics=False).get('term_vectors', {})\n",
    "    tf = {} # tf[field][t] holds the frequency of term `t` in a given document field; extract the values from `tv`\n",
    "    fieldlen = {} # length of the field: fieldlen[field] = sum(tf[field].values())\n",
    "    \n",
    "    score = 0  # holds log P(q|d)\n",
    "    for term in qterms:  # this is the main summation over query terms\n",
    "        ptd = 0  # compute P(t|\\theta_d) as a mixture of field LMs\n",
    "        for field in FIELDS:  # field corresponds to i in the above equations\n",
    "            ptdi = tf[field][term] / fieldlen[field]  # empirical field LM P(t|d_i)\n",
    "            ptci = BG_LM[field].get_prob(term)  # background field LM P(t|C_i)\n",
    "            pttdi = (1 - LAMBDA) * ptdi + LAMBDA * ptci  # P(t|\\theta_{d_i}) with JM smoothing\n",
    "            ptd += FIELD_WEIGHT[field] * pttdi\n",
    "        score += math.log(ptd) \n",
    "    return score        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring all queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "\n",
    "for query in queries:\n",
    "    # Top 200 documents retrieved using default Elasticsearch method\n",
    "    res = es.search(index=INDEX_NAME, q=query, df=CONTENT_FIELD, _source=False, size=200).get('hits', {})\n",
    "    \n",
    "    # Extract preprocessed query terms\n",
    "    tokens = es.indices.analyze(index=INDEX_NAME, body=query)['tokens']\n",
    "    qterms = []  # you need to extract the terms from tokens\n",
    "    \n",
    "    # Re-rank documents using MLM\n",
    "    scores = {}\n",
    "    for doc in res.get(\"hits\"):\n",
    "        doc_id = doc.get(\"_id\")\n",
    "        scores[doc_id] = score(doc_id, qterms)\n",
    "    \n",
    "    # Output top-100 docs with highest scores to file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
